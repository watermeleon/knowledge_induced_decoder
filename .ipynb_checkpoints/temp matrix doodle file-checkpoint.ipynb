{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8230ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c1a93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89a08a0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [10, 1, 64, 64].  Tensor sizes: [10, 64, 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7834/1478459407.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# compute the combi mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcombi_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtot_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtot_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcombi_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_pref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_pref\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisible_matrix_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mcombi_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_self_attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombi_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (10) at non-singleton dimension 1.  Target sizes: [10, 1, 64, 64].  Tensor sizes: [10, 64, 64]"
     ]
    }
   ],
   "source": [
    " \n",
    "seq_len = 16\n",
    "max_pref = 64\n",
    "tot_seq = seq_len + max_pref\n",
    "\n",
    "visible_matrix_batch = torch.ones((10, max_pref, max_pref))\n",
    "mask_self_attention = torch.ones((10,seq_len, seq_len))*2\n",
    "\n",
    "# compute the combi mask\n",
    "combi_mask = torch.zeros((10,1,tot_seq, tot_seq))\n",
    "combi_mask[:,:,:max_pref,:max_pref] = visible_matrix_batch\n",
    "combi_mask[:,:, -seq_len:, -seq_len:] = mask_self_attention\n",
    "print(combi_mask[0])\n",
    "seg_batch = b == 1\n",
    "for i, seg_item in enumerate(seg_batch):\n",
    "    combi_mask[i,:,max_pref:, :max_pref][:,seg_item] = 1\n",
    "#     temp1 = 1\n",
    "#     print(temp1.size())\n",
    "print(combi_mask[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f639f555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.Size([10, 64])\n",
      "tensor([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[ True, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False],\n",
      "        [False,  True,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7834/3722919993.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(torch.tensor(b[:2]).gt(0))\n"
     ]
    }
   ],
   "source": [
    "a= torch.tensor(list(range(10)))\n",
    "print(a)\n",
    "b = torch.zeros((10, max_pref))\n",
    "# b[]\n",
    "# print(b[:,a.T] == torch.ones((seq_len)))\n",
    "for i,val in enumerate(a):\n",
    "    b[i,val]=1\n",
    "print(b.size())\n",
    "b[:,2] = 1\n",
    "print(b[:2])\n",
    "print(torch.tensor(b[:2]).gt(0))\n",
    "\n",
    "# b = torch.zeros((10,seq_len, max_pref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "938ae498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "14 1\n",
      "10 10\n"
     ]
    }
   ],
   "source": [
    "a= [['a', 'restaurant', 'has', 'modern', 'wooden', 'tables', 'and', 'chairs', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['a', 'long', 'restaurant', 'table', 'with', 'rattan', 'rounded', 'back', 'chairs', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['a', 'long', 'table', 'with', 'a', 'plant', 'on', 'top', 'of', 'it', 'surrounded', 'with', 'wooden', 'chairs'], ['a', 'long', 'table', 'with', 'a', 'flower', 'arrangement', 'in', 'the', 'middle', 'for', 'meetings', '[PAD]', '[PAD]'], ['a', 'table', 'is', 'adorned', 'with', 'wooden', 'chairs', 'with', 'blue', 'accents', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['a', 'man', 'preparing', 'desserts', 'in', 'a', 'kitchen', 'covered', 'in', 'frosting', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['a', 'chef', 'is', 'preparing', 'and', 'decorating', 'many', 'small', 'pastries', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['a', 'baker', 'prepares', 'various', 'types', 'of', 'baked', 'goods', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['a', 'close', 'up', 'of', 'a', 'person', 'grabbing', 'a', 'pastry', 'in', 'a', 'container', '[PAD]', '[PAD]'], ['close', 'up', 'of', 'a', 'hand', 'touching', 'various', 'pastries', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']]\n",
    "b =  [[[101, 1037, 4825, 2038, 2715, 4799, 7251, 1998, 8397, 0, 0, 0, 0, 0, 0, 102]], [[101, 1037, 2146, 4825, 2795, 2007, 9350, 5794, 8352, 2067, 8397, 0, 0, 0, 0, 0, 102]], [[101, 1037, 2146, 2795, 2007, 1037, 3269, 2006, 2327, 1997, 2009, 5129, 2007, 4799, 8397, 102]], [[101, 1037, 2146, 2795, 2007, 1037, 6546, 6512, 1999, 1996, 2690, 2005, 6295, 0, 0, 102]], [[101, 1037, 2795, 2003, 19189, 2007, 4799, 8397, 2007, 2630, 24947, 0, 0, 0, 0, 102]], [[101, 1037, 2158, 8225, 18064, 2015, 1999, 1037, 3829, 3139, 1999, 10097, 2075, 0, 0, 0, 0, 102]], [[101, 1037, 10026, 2003, 8225, 1998, 25545, 5844, 2116, 2235, 2627, 5134, 0, 0, 0, 0, 0, 102]], [[101, 1037, 6243, 20776, 2536, 4127, 1997, 17776, 5350, 0, 0, 0, 0, 0, 0, 102]], [[101, 1037, 2485, 2039, 1997, 1037, 2711, 9775, 1037, 27060, 1999, 1037, 11661, 0, 0, 102]], [[101, 2485, 2039, 1997, 1037, 2192, 7244, 2536, 2627, 5134, 0, 0, 0, 0, 0, 0, 102]]]\n",
    "c =   [[101, 1037, 4825, 2038, 2715, 4799, 7251, 1998, 8397, 0, 0, 0, 0, 0, 0, 102], \\\n",
    "       [101, 1037, 2146, 4825, 2795, 2007, 9350, 5794, 8352, 2067, 8397, 0, 0, 0, 0, 0, 102],\\\n",
    " [101, 1037, 2146, 2795, 2007, 1037, 3269, 2006, 2327, 1997, 2009, 5129, 2007, 4799, 8397, 102], \\\n",
    " [101, 1037, 2146, 2795, 2007, 1037, 6546, 6512, 1999, 1996, 2690, 2005, 6295, 0, 0, 102], \\\n",
    "       [101, 1037, 2795, 2003, 19189, 2007, 4799, 8397, 2007, 2630, 24947, 0, 0, 0, 0, 102],\\\n",
    " [101, 1037, 2158, 8225, 18064, 2015, 1999, 1037, 3829, 3139, 1999, 10097, 2075, 0, 0, 0, 0, 102],\\\n",
    " [101, 1037, 10026, 2003, 8225, 1998, 25545, 5844, 2116, 2235, 2627, 5134, 0, 0, 0, 0, 0, 102],\\\n",
    " [101, 1037, 6243, 20776, 2536, 4127, 1997, 17776, 5350, 0, 0, 0, 0, 0, 0, 102], \\\n",
    " [101, 1037, 2485, 2039, 1997, 1037, 2711, 9775, 1037, 27060, 1999, 1037, 11661, 0, 0, 102],\\\n",
    " [101, 2485, 2039, 1997, 1037, 2192, 7244, 2536, 2627, 5134, 0, 0, 0, 0, 0, 0, 102]]\n",
    "\n",
    "print(len(c))\n",
    "for j in c:\n",
    "    print(len(c))\n",
    "for i in range(len(a)):\n",
    "    print(len(a[i]), len(b[i]))\n",
    "print(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a8a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "547e6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e6eead2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0] 11\n"
     ]
    }
   ],
   "source": [
    "a = list(a)\n",
    "diff = 2\n",
    "b = a[:-1] + [1]*diff + a[-1:]\n",
    "# a[-1-diff:-1] = 1\n",
    "print(b, len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b51d853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(a[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a0895ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros((4,5))\n",
    "b = torch.ones((4,2))\n",
    "c = torch.cat((a,b), -1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7667b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6059, 0.4555, 0.8783, 0.8304, 0.3929],\n",
      "        [0.1491, 0.1012,    nan,    nan,    nan],\n",
      "        [0.8277, 0.2712, 0.7819, 0.8672, 0.1937],\n",
      "        [0.0092, 0.6693, 0.6107, 0.0349, 0.0348]])\n",
      "tensor(nan) tensor([[0.6059, 0.4555, 0.8783, 0.8304, 0.3929],\n",
      "        [0.1491, 0.1012,    nan,    nan,    nan],\n",
      "        [0.8277, 0.2712, 0.7819, 0.8672, 0.1937],\n",
      "        [0.0092, 0.6693, 0.6107, 0.0349, 0.0348]])\n",
      "tensor([0.1491, 0.1012,    nan,    nan,    nan])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "c = torch.rand((4,5))\n",
    "# print(c[1,2:])\n",
    "c[1][2:] = float('nan')\n",
    "nan = float('nan')\n",
    "print(c)\n",
    "for row in c:\n",
    "    if nan in row:\n",
    "        prin(row)\n",
    "#     print(((row == float('nan')).nonzero(as_tuple=True)[0]))\n",
    "# print(torch.all(tensor.isnan()))\n",
    "print(c.min(), c)\n",
    "print(c[1])\n",
    "print(0.3080 in c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afa3a429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan) tensor([[0.6059, 0.4555, 0.8783, 0.8304, 0.3929],\n",
      "        [0.1491, 0.1012,    nan,    nan,    nan],\n",
      "        [0.8277, 0.2712, 0.7819, 0.8672, 0.1937],\n",
      "        [0.0092, 0.6693, 0.6107, 0.0349, 0.0348]])\n",
      "tensor([0.1491, 0.1012,    nan,    nan,    nan])\n",
      "False\n",
      "tensor([[False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "print(c.min(), c)\n",
    "print(c[1])\n",
    "print(c[1][3] in c[1])\n",
    "print(c == nan)\n",
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08aa626e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is tensor([[[6.1297e-02, 9.1283e-01, 9.2321e-01, 8.3572e-01, 3.6196e-01],\n",
      "         [9.5948e-01, 3.9041e-01, 5.8421e-01, 5.0958e-01, 3.8475e-01],\n",
      "         [5.0597e-01, 2.8263e-01, 7.4737e-01, 2.8065e-01, 2.4815e-01],\n",
      "         [5.6101e-01, 9.1937e-01, 6.9929e-01, 9.6770e-01, 8.4582e-01]],\n",
      "\n",
      "        [[8.9212e-01, 8.0881e-01, 1.6093e-02,        nan,        nan],\n",
      "         [8.8453e-02, 3.6809e-01, 3.3275e-02,        nan,        nan],\n",
      "         [2.1166e-01, 5.2706e-01, 2.2238e-02,        nan,        nan],\n",
      "         [1.9854e-04, 6.5533e-01, 1.2669e-01,        nan,        nan]],\n",
      "\n",
      "        [[5.4155e-01, 9.4485e-01, 4.8415e-01,        nan,        nan],\n",
      "         [4.5374e-01, 8.2183e-01, 5.6936e-03,        nan,        nan],\n",
      "         [2.7041e-01, 6.5814e-01, 7.8268e-02,        nan,        nan],\n",
      "         [6.0500e-01, 4.3197e-01, 9.8712e-01,        nan,        nan]]]) torch.Size([3, 4, 5])\n",
      "1 0 3\n",
      "1 1 3\n",
      "1 2 3\n",
      "1 3 3\n",
      "2 0 3\n",
      "2 1 3\n",
      "2 2 3\n",
      "2 3 3\n"
     ]
    }
   ],
   "source": [
    "out = torch.rand((3,4,5))\n",
    "out[1:,:,3:] = nan\n",
    "# for i, l in enumerate(self.layers):\n",
    "print(\"Input is\", out, out.size())\n",
    "for p, item in enumerate(out):\n",
    "    for k, row in enumerate(item):\n",
    "        for l, col in enumerate(row):\n",
    "            if torch.isnan(col):\n",
    "                print(p,k,l)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a95fc84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis =[  3,   4,   5,   6,   7,   4,   5,   2,   1,   0,   4,   3,   2,   3,\n",
    "           2,   3,   2,   5,   6,   7,   6,   7,   8,   9,   6,   7,   8,   9,\n",
    "           6,   5,   4,   7,   8,   9,   5,   4,   3,   7,   6,   5,   4,   8,\n",
    "           9,  10,  11,  12,   8,   9,  10, 127, 127, 127, 127, 127, 127, 127,\n",
    "         127, 127, 127, 127, 127, 127, 127, 127,  64,  65,  66,  67,  68,  69,\n",
    "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81]\n",
    "lis.index(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df191c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "lis2.index(False)\n",
    "print(0*nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dce6a774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor([-1,- np.inf, nan])\n",
    "m.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72db6cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7834/930962350.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  lis = torch.tensor(lis)\n"
     ]
    }
   ],
   "source": [
    "lis = torch.tensor(lis)\n",
    "a = (lis != 0).unsqueeze(-1).float() \n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4b199fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "17\n",
      "28\n",
      "37\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 17, 28, 37]\n"
     ]
    }
   ],
   "source": [
    "temp = [False, False, False, False, False, False, False, False, False, False,\n",
    "        False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
    "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
    "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
    "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "         True,  True,  True,  True]\n",
    "idxlist = []\n",
    "while False in temp:\n",
    "    idx = temp.index(False)\n",
    "    print(idx)\n",
    "    idxlist.append(idx)\n",
    "    temp[idx] = True\n",
    "print(repr(idxlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb1958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3955e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_prefix_caption",
   "language": "python",
   "name": "clip_prefix_caption"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
