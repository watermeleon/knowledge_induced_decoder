{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d32c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8190a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For nocaps:\n",
    "annFile='../Datasets/NoCaps/nocaps_val_4500_captions.json'\n",
    "resFile = \"../knowledge_induced_decoder/generated_sentences/vit_KG_pll_base_enc1_pttok_rc3_coco_beam_1_Nocaps.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739dbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result for coco\n",
    "annotation_file = 'captions_val2014.json'\n",
    "# results_file = 'captions_val2014_fakecap_results.json'\n",
    "# results_file = \"../../generated_sentences/vit_KG_pll_base_enc1_pttok_rc3_coco_beam_1.json\"\n",
    "results_file = \"../../generated_sentences/vit_KG_vanil_base_enc1_final_org_SegParam2_coco.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdce2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"coco\"\n",
    "# model_file = \"../../generated_sentences/vit_kw_pll_base_enc1_final_org_SegParam2\"\n",
    "model_file = \"../../generated_sentences/scst_gen/vit_KG_pll_base_enc1_final_org_SegParam2\"\n",
    "\n",
    "if datatype == \"coco\":\n",
    "    annotation_file = 'captions_val2014.json'\n",
    "else:\n",
    "    annotation_file='../../../Datasets/NoCaps/nocaps_val_4500_captions.json'\n",
    "results_file = model_file + \"_\" +datatype + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01fd83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tabulate\n",
    "import os.path\n",
    "from os import path\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "def load_json(filename):\n",
    "    \"Wrapper function to load JSON data.\"\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c332fcc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "axolotl_sentences/promptsets\n",
      "loading annotations into memory...\n",
      "Done (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.10s)\n",
      "creating index...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13852/2772742371.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcoco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mcoco_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcoco_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCOEvalCap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoco_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcoco_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImgIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clip_prefix_caption/lib/python3.9/site-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36mloadRes\u001b[0;34m(self, resFile)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/clip_prefix_caption/lib/python3.9/site-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36mcreateIndex\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mann\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mimgToAnns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0manns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'images'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "annotation_file = 'captions_val2014.json'\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "all_capfiles = glob(\"../../generated_sentences/*.json\", recursive = True)\n",
    "all_capfiles.sort()\n",
    "print(len([file for file in all_capfiles if \"coco\" in file]))\n",
    "basefile = \"../../generated_sentences/vit_KG_pll_base_enc1_final_org_SegParam2_coco.json\".split(\"_\")\n",
    "basename = \"axolotl\"\n",
    "metric_names = [\"Bleu_1\", \"Bleu_4\", \"METEOR\", \"ROUGE_L\", \"CIDEr\", \"SPICE\"]\n",
    "table = [[\"model_name\"] +metric_names]\n",
    "for file in all_capfiles:\n",
    "    if \"coco\" in file:\n",
    "#         print(file)\n",
    "        splitfile = file.split(\"_\")\n",
    "        difffile = [word for word in splitfile if word not in basefile]\n",
    "        newname = basename+\"_\" +\"_\".join(difffile)\n",
    "        print(newname)\n",
    "        coco = COCO(annotation_file)\n",
    "        coco_result = coco.loadRes(file)\n",
    "        coco_eval = COCOEvalCap(coco, coco_result)\n",
    "        coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "        coco_eval.evaluate()\n",
    "        entry = [newname]\n",
    "        model_res = list(np.array([coco_eval.eval[metr] for metr in metric_names])*100)\n",
    "        entry += model_res\n",
    "        print(model_res)\n",
    "        table.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fee37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name             Bleu_1    Bleu_4    METEOR    ROUGE_L    CIDEr    SPICE\n",
      "-------------------  --------  --------  --------  ---------  -------  -------\n",
      "axolotl_NoRel         76.9148   35.5604   27.1589    56.4772  113.648  20.1768\n",
      "axolotl_RCl2r         75.9093   35.177    27.0816    56.0693  112.945  20.2326\n",
      "axolotl_SEGKW         76.8176   35.5387   27.2002    56.467   113.349  20.2482\n",
      "axolotl_              81.7776   37.2962   27.5949    57.3121  121.197  20.5645\n",
      "axolotl_plldec1       76.4629   34.831    27.2973    56.4239  112.645  20.3951\n",
      "axolotl_posidx1       76.29     34.9314   27.0813    56.2933  112.974  20.2206\n",
      "axolotl_wo_pttokemb   76.6191   35.4325   27.151     56.5817  113.404  20.282\n",
      "axolotl_stck          76.6666   35.6669   27.0801    56.432   112.85   20.2195\n",
      "axolotl_kw            80.9396   36.0857   27.5111    56.8609  119.802  20.4818\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c921114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create coco object and coco_result object\n",
    "coco = COCO(annotation_file)\n",
    "coco_result = coco.loadRes(results_file)\n",
    "coco_eval = COCOEvalCap(coco, coco_result)\n",
    "coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "coco_eval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print output evaluation scores\n",
    "for metric, score in coco_eval.eval.items():\n",
    "    print(f'{metric}: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c17069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip_prefix_caption",
   "language": "python",
   "name": "clip_prefix_caption"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
